{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fc03283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.layers import Input, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import ReLU, AvgPool2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ad9fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# print(\"Num GPUs Available\", len(physical_devices))\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "#for only running it in CPU\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f27c18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(spectrogramFilePath, csvFilePath):\n",
    "    \"\"\"\n",
    "    This function will read the spectrogram images of the folder and load as tf.numpy array\n",
    "    \n",
    "    Attributes:\n",
    "        spectrogramFilePath (string): The folder path of spectrograms location\n",
    "        csvFilePath (string): The complete .csv file path for defining the classification\n",
    "    \n",
    "    Returns:\n",
    "        spectrograms (numpy arrays): Values of the spectrograms\n",
    "        classifications (numpy array): Classification value\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset = pd.read_csv(csvFilePath)\n",
    "    classifications = dataset.iloc[:, -1].values\n",
    "    \n",
    "    allItemsInFolder = os.listdir(spectrogramFilePath)\n",
    "    files = [item for item in allItemsInFolder if os.path.isfile(os.path.join(spectrogramFilePath, item))]\n",
    "    fileCount = len(files)\n",
    "    \n",
    "    #the followung is image data set \n",
    "    numpyData = np.empty((fileCount, 256, 256))\n",
    "    \n",
    "    for i in range(0, fileCount):        \n",
    "        #following is for image data reading\n",
    "        actualFilePath = spectrogramFilePath + f'/NUMPY_{i}.npy'\n",
    "        npArray = np.load(actualFilePath)\n",
    "        numpyData[i] = npArray    \n",
    "    \n",
    "    return numpyData, classifications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f8d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = readData(spectrogramFilePath = 'D:/Project Data/spectrograms/numpy',\n",
    "                      csvFilePath = 'D:/Project Data/Individual Project Data of Mashnunul Huq/Actual Data Taking/Training Data/trainingData.csv')\n",
    "train_data, validation_data, train_labels, validation_labels = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# validationData, validationLabels = readData(spectrogramFilePath='D:/Project Data/spectrograms/vnumpy',\n",
    "#                                            csvFilePath='D:/Project Data/Individual Project Data of Mashnunul Huq/Actual Data Taking/Validation Data/validationData.csv')\n",
    "# testingData, testingLabels = readData(spectrogramFilePath='D:/Project Data/spectrograms/tnumpy',\n",
    "#                                            csvFilePath='D:/Project Data/Individual Project Data of Mashnunul Huq/Actual Data Taking/Testing Data/testingData.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0998f642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8249, 256, 256)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cea1cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.60550904 0.60550904 0.60550904 ... 0.56260999 0.56260999 0.56260999]\n",
      " [0.34153377 0.34153377 0.34153377 ... 0.22736858 0.22736858 0.22736858]\n",
      " [0.28059548 0.28059548 0.28059548 ... 0.29401781 0.29401781 0.29401781]\n",
      " ...\n",
      " [0.1922555  0.1922555  0.1922555  ... 0.20522058 0.20522058 0.20522058]\n",
      " [0.08175367 0.08175367 0.08175367 ... 0.10403649 0.10403649 0.10403649]\n",
      " [0.06609949 0.06609949 0.06609949 ... 0.11411158 0.11411158 0.11411158]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4a41f6",
   "metadata": {},
   "source": [
    "CNN Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d01806",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(256,256,1)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(256, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9473524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 62, 62, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 50176)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                3211328   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,599,233\n",
      "Trainable params: 3,599,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "592f746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "819c14c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "258/258 - 200s - loss: 0.5659 - accuracy: 0.6741 - val_loss: 0.2581 - val_accuracy: 0.8956 - 200s/epoch - 775ms/step\n",
      "Epoch 2/10\n",
      "258/258 - 202s - loss: 0.2610 - accuracy: 0.8936 - val_loss: 0.0934 - val_accuracy: 0.9796 - 202s/epoch - 784ms/step\n",
      "Epoch 3/10\n",
      "258/258 - 200s - loss: 0.1205 - accuracy: 0.9702 - val_loss: 0.0272 - val_accuracy: 0.9960 - 200s/epoch - 776ms/step\n",
      "Epoch 4/10\n",
      "258/258 - 201s - loss: 0.0757 - accuracy: 0.9852 - val_loss: 0.0174 - val_accuracy: 0.9978 - 201s/epoch - 778ms/step\n",
      "Epoch 5/10\n",
      "258/258 - 202s - loss: 0.0663 - accuracy: 0.9859 - val_loss: 0.0158 - val_accuracy: 0.9960 - 202s/epoch - 781ms/step\n",
      "Epoch 6/10\n",
      "258/258 - 202s - loss: 0.0613 - accuracy: 0.9865 - val_loss: 0.0126 - val_accuracy: 0.9956 - 202s/epoch - 783ms/step\n",
      "Epoch 7/10\n",
      "258/258 - 201s - loss: 0.0420 - accuracy: 0.9890 - val_loss: 0.0119 - val_accuracy: 0.9978 - 201s/epoch - 780ms/step\n",
      "Epoch 8/10\n",
      "258/258 - 202s - loss: 0.0335 - accuracy: 0.9919 - val_loss: 0.0098 - val_accuracy: 0.9978 - 202s/epoch - 783ms/step\n",
      "Epoch 9/10\n",
      "258/258 - 202s - loss: 0.0416 - accuracy: 0.9908 - val_loss: 0.0112 - val_accuracy: 0.9978 - 202s/epoch - 783ms/step\n",
      "Epoch 10/10\n",
      "258/258 - 203s - loss: 0.0300 - accuracy: 0.9941 - val_loss: 0.0087 - val_accuracy: 0.9989 - 203s/epoch - 787ms/step\n",
      "2015.5018231868744\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "model.fit(\n",
    "    x = train_data,\n",
    "    y = train_labels,\n",
    "    epochs=10,\n",
    "    verbose=2,\n",
    "    validation_data=(validation_data, validation_labels)\n",
    ")\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b496531",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:/Individual Project/person_detection_signal_onlyCNN_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0def07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnModel = load_model('D:/Individual Project/person_detection_signal_onlyCNN_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
